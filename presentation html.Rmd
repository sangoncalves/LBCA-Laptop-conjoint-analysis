---
title: "Laboratory of Consumer and Business Analytics"
subtitle: "Conjoint analysis - Laptop Dataset"
author: 
  - "Nisha Antony"
  - "Sander Martins"
date: "27/01/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r Loading Libraries, include=FALSE}
library(mlogit)
library(dplyr)
library(ggplot2)
library(MASS)
library(lattice)
```

```{r Loading Dataset, include=FALSE}
laptops = read.csv("Dataset/laptops.csv", sep=";")

```


<!-- Here we are converting the quantitative variables to qualitative before fitting it into the model. WE set 4GB, 126GB, i3, 0.8Kg as ref level for RAM, Memory, Proc and weight resp.This helps us to see how preferences changes overtime when we have higher config as an alternative-->
```{r Preparing data, include=FALSE}
laptops$Price       <- as.factor(laptops$Price)
laptops$RAM         <- factor(laptops$RAM, levels=c( "4GB", "8GB", "16GB", "32GB" ))
laptops$Memory      <- factor(laptops$Memory, levels=c( "126GB", "256GB", "512GB", "1T" ))
laptops$Processor   <- factor(laptops$Processor, levels=c( "i3", "i5", "i7", "i9" ))
laptops$Weight      <- factor(laptops$Weight, levels=c( "0.8kg", "1kg", "1.2kg", "1.5kg" ))
laptops$ScreenSize  <- as.factor(laptops$ScreenSize) 
laptops$alt         <- factor(laptops$alt, levels=c("1", "2", "3", "4"))
```
# Agenda
* Project Description <br/>
* Summary of all the analysis to be presented <br/>
* Dataset description <br/>
* Dataset balanced and Association of attributes<br/>
* Models to fit our data<br/>
* Choosing models part 1<br/>
* Are our users homogeneous?<br/>
* Correlated models<br/>
* Choosing models part 2<br/>
* Preference share of the users<br/>
* Product profiles<br/>
* Conclusion<br/>



## Project Description

The objective of this project is to have an understanding of conjoint analysis and demonstrate some of the conclusion that we be can found using this analysis. In this project, we will analyze the preferences of an individual when they purchase a laptop. As you already know, we have several options in the market when it comes to laptops. A customer usually does a thorough research before he/she makes the purchase. The final decision depends on several attributes of the product and its relevance to the customer. We atudy the relationship between the choice and product attrinutes. 

## Dataset description
Our dataset represents the generated answers to questionnaires regarding the choice of laptops. 

Our dataset is represented in a long format, in other words we have a row for each alternatives. We have 4 alternatives each for 7500 questions and 4 levels for each attributes. 

```{r Data description, echo=FALSE}
summary(laptops)
```


## Dataset balanced and Association of attributes

In this part, we check whether the attributes are well balanced.

```{r echo=FALSE}
# To check balance, he used this function
sapply(laptops, table)
```

Here, the attributes are properly balanced that is the frequencies across each levels of the attributes are equally distributed. There is no over/under representation in level of attributes.  

Now we can look into the association of attributes with choice made y the respondent. The xtabs() which provides the joint distribution between two variables is used here.
```{r}
xtabs(choice ~ Price, data=laptops)
xtabs(choice ~ RAM, data=laptops)
xtabs(choice ~ Memory, data=laptops)
xtabs(choice ~ Processor, data=laptops)
xtabs(choice ~ Weight, data=laptops)
xtabs(choice ~ ScreenSize, data=laptops)
```


From the joint distribution obtained, we can see that the customers highly prefer laptops with bigger screensize, high memory a decent RAM of 8GB and i5 processor and are looking for products mostly at price range of 0.7K. A very few are opting for laptops with 12" screen and are interested in spending 2K on a laptop.

## Models to fit our data

### Multinomial Logit Model(MNL)

From the dataset, we can gather that the respondent had 4 alternatives to make his/her final choice; implying that the dependent variable is a qualitative multinomial variable with 4 levels. Multinomial Logit model is an appropriate one to fit this kind of data. MNL gives the measurement of association between each attributes and respondent choice.

We use mlogit() function to fit the MNL model. However, the function requires us to organize the data in a special format by using dfidx(). 
```{r}
laptops$Price       <- factor(laptops$Price, levels=c( "0.7", "1", "1.5", "2" ))
laptops$RAM         <- factor(laptops$RAM, levels=c( "4GB", "8GB", "16GB", "32GB" ))
laptops$Memory      <- factor(laptops$Memory, levels=c( "126GB", "256GB", "512GB", "1T" ))
laptops$Processor   <- factor(laptops$Processor, levels=c( "i3", "i5", "i7", "i9" ))
laptops$Weight      <- factor(laptops$Weight, levels=c( "0.8kg", "1kg", "1.2kg", "1.5kg" ))
laptops$ScreenSize  <- factor(laptops$ScreenSize, levels=c( "12", "13", "14", "16" ))
laptops$alt         <- factor(laptops$alt, levels=c("1", "2", "3", "4"))
```


```{r}
laptops.mlogit <- dfidx(laptops, idx = list(c("ques", "resp.id"), "alt"), drop.index=F, levels=c(1,2,3,4))
```

Now, we asess how attributes affects the choice. In the first model, we will consider the intercept parameters so that we can test the restrictions on them by comparing two models.

```{r}
lm1 <- mlogit(choice ~ Price + RAM + Memory + Processor + Weight + ScreenSize , data = laptops.mlogit)
summary(lm1)
```

In the summary of lm1 model, we can see that the model estimate coefficient of RAM32GB, RAM4GB and RAM8GB with respect to RAM16GB laptops measuring the preference. The laptops with 8GB RAM are more attracted to than RAM of 16GB whereas RAM of 32GB is the least attracted one. Similarly, in terms of memory the coeffients are estimated with respect to Memory126GB. In this case, laptops with 1TB memory has higher preference compared to 126GB When it comes to processors, i3 is taken as the reference value and from the est. coefficient, we can see that i5 is more preferred. The 12-inch and 0.7k is the reference point for screensize and price respectively. Among those attributes, we can see that 16 inch models are far more prefered with respect to 12 inch ones and for the price range, 0.7k itself is most preferred. The est. intercepts provide the preferences for the positions of the alternatives in each question. Here the values corresponding to those intercepts are very small implying that position of alternatives doesn't have much significance. 

In order to formally test this, we fit another model without intercept parameters and perform a likelihood ratio test comparing both models.

```{r}
lm2 <- mlogit(choice ~ Price + RAM + Memory + Processor + Weight + ScreenSize | -1, data = laptops.mlogit)
summary(lm2)
```

## Choosing models part 1
```{r echo=FALSE}
# print("Testing if the models are siginificantly equivalent")
lrtest(lm1, lm2)
# print("Since p-value is higher than our significance level (0.05), than we do not have enough evidence to reject null hypothesys.")
```

Here we compare the MNL model with and without estimated intercepts. The comparison between the lm1 and the lm2 with no intercepts leads to a p-value of 0.5133. Since we have a high p-value, we can conclude that the two models are not significantly different in terms of
goodness of fit. This indicates that the alternative specific constants are not necessary to adequately model the data.

```{r Willingness to pay (not available for our data), eval=FALSE, include=FALSE}
print("Analyze model with price as qualitative vs quantitative")
lm3 <- mlogit(choice ~  as.numeric(as.character(Price)) + RAM + Memory + Processor + Weight + ScreenSize | -1, data = laptops.mlogit)
summary(lm3)
lrtest(lm3, lm2)
# print("since our p-value is smaller than our significance level(0.05), we cannot use price as quantitative variable. This means that we cannot analyze the willingness-to-pay for each level's attribute.")
```

## Popular profiles (top 15)
```{r Frequency table, include=FALSE}
#adding index
laptops.chosen <- filter(laptops,laptops$choice == "1")
laptops.indexed <- laptops.chosen
laptops.indexed$id <- paste(as.character(laptops.indexed$Price),"-",
                            as.character(laptops.indexed$RAM),"-",
                            as.character(laptops.indexed$Memory),"-",
                            as.character(laptops.indexed$Processor),"-",
                            as.character(laptops.indexed$Weight),"-",
                            as.character(laptops.indexed$ScreenSize), sep = "")

# Profiles more "popular" (top chosen)
freqtable <- table(laptops.indexed$id)
df <- as.data.frame.table(freqtable)
df <- df %>% as.data.frame() %>% top_n(15, Freq) %>% rename(Profiles = Var1)
df <- df[1:15,]
df <- transform(df, Profiles=reorder(Profiles, -Freq)) 
theme_set(theme_classic())
```

```{r Profiles Graph, echo=FALSE}
## Plot
g <- ggplot(df, aes(Profiles, Freq))
g + geom_bar(stat="identity", width = 0.5, fill="tomato2") + 
  labs(title="Profiles counting", 
       caption="Frequency of profiles") +
  theme(axis.text.x = element_text(angle=65, vjust=0.6))

```

```{r Function selecting profiles, include=FALSE}
attributes <- list(Price=names(table(laptops.mlogit$Price)),
                   RAM=names(table(laptops.mlogit$RAM)),
                   Memory=names(table(laptops.mlogit$Memory)),
                   Processor=names(table(laptops.mlogit$Processor)),
                   Weight=names(table(laptops.mlogit$Weight)),
                   ScreenSize=names(table(laptops.mlogit$ScreenSize)))
allDesign <- expand.grid(attributes) 

ProductSelection <- function(Price,RAM,Memory,Processor,Weight,ScreenSize){
  ram <-  paste(as.character(RAM), "GB", sep = "")
  if(Memory==1) memory <- paste(as.character(Memory), "T", sep = "") else memory <-  paste(as.character(Memory), "GB", sep = "")
  processor <-  paste('i',as.character(Processor), sep = "")
  weight <-  paste(as.character(Weight), "kg", sep = "")
  
  return(filter(allDesign, Price == {{Price}}, RAM == {{ram}}, Memory == {{ memory }}, Processor == {{ processor }}, Weight == {{ weight }}, ScreenSize == {{ ScreenSize }}))
}
```

## Profiles chosen 
```{r include=FALSE}
#Entry market
entry1 <- ProductSelection(Price = 0.7, RAM = 4,Memory = 126,Processor = 3, Weight = 0.8,ScreenSize = 12)
entry2 <- ProductSelection(Price = 1, RAM = 4,Memory = 126,Processor = 3, Weight = 1.2,ScreenSize = 13)

#Mid market
mid1 <- ProductSelection(Price = 1, RAM = 8,Memory = 256,Processor = 5, Weight = 1, ScreenSize = 13)
mid2 <- ProductSelection(Price = 1.5, RAM = 16,Memory = 512,Processor = 7, Weight = 1.5,ScreenSize = 16)

#High end market
high1 <- ProductSelection(Price = 2, RAM = 16,Memory = 512, Processor = 7, Weight = 1.2,ScreenSize = 16)
high2 <- ProductSelection(Price = 2, RAM = 32,Memory = 1, Processor = 9, Weight = 1.5,ScreenSize = 14)

profiles <- rbind(entry1, entry2, mid1, mid2, high1, high2)
```

```{r echo=FALSE}
print(profiles)
```

```{r Predict Function, include=FALSE}
predict.mnl <- function(model, data) {
  # Function for predicting preference shares from a MNL model 
  # model: mlogit object returned by mlogit()
  # data: a data frame containing the set of designs for which you want to 
  #       predict shares.  Same format at the data used to estimate model. 
  data.model <- model.matrix(update(model$formula, 0 ~ .), data = data)[,-1]
  logitUtility <- data.model%*%model$coef
  share <- exp(logitUtility)/sum(exp(logitUtility))
  cbind(share, data)
}
```

## Preference share prediction (Not representing sales)
```{r echo=FALSE}
predict.mnl(lm2, profiles)
```

```{r include=FALSE}
sensitivity.mnl <- function(model, attrib, base.data, competitor.data) {
  # Function for creating data for a preference share-sensitivity chart
  # model: mlogit object returned by mlogit() function
  # attrib: list of vectors with attribute levels to be used in sensitivity
  # base.data: data frame containing baseline design of target product
  # competitor.data: data frame contining design of competitive set
  data <- rbind(base.data, competitor.data)
  base.share <- predict.mnl(model, data)[1,1]
  share <- NULL
  for (a in seq_along(attrib)) {
    for (i in attrib[[a]]) {
      data[1,] <- base.data
      data[1,a] <- i
      share <- c(share, predict.mnl(model, data)[1,1])
    }
  }
  data.frame(level=unlist(attrib), share=share, increase=share-base.share)
}

base.data <- profiles[5,]
competitor.data <- profiles[-5,]
tradeoff <- sensitivity.mnl(lm2, attributes, base.data, competitor.data)
```

## Trade-off graph
```{r echo=FALSE}
print(tradeoff)
barplot(tradeoff$increase, horiz=FALSE, names.arg=tradeoff$level,
        ylab="Change in Share for the Planned Product Design", 
        ylim=c(-0.1,0.4))
grid(nx=NA, ny=NULL)
```

## Are our users homogeneous?
```{r include=FALSE}
lm2.rpar <- rep("n", length=length(lm2$coef))
names(lm2.rpar) <- names(lm2$coef)
lm2.rpar
```

```{r}
lm2.mixed <- mlogit(choice ~ Price + RAM + Memory + Processor + Weight + ScreenSize  | -1, 
                   data = laptops.mlogit, 
                   panel=TRUE, rpar = lm2.rpar, correlation = FALSE)
summary(lm2.mixed)
```

## Correlated models
```{r eval=FALSE, include=FALSE}
# We can get a visual summary of the distribution of random effects and hence of the level of heterogeneity
layout(matrix(c(3,3,2,3), 2, 2, byrow = TRUE))
#par(mfrow=c(2,2))
plot(lm2.mixed)
```

```{r}
#comparing the sign of the quantiles we can identify that Processori5 and Weight1.5kg have different signs, which could imply into heterogeneity
par(mfrow=c(2,2))
processor5.distr <- rpar(lm2.mixed, "Processori5")
summary(processor5.distr)
mean(processor5.distr)
med(processor5.distr)
plot(processor5.distr)


Weight1.5kg.distr <- rpar(lm2.mixed, "Weight1.5kg")
summary(Weight1.5kg.distr)
mean(Weight1.5kg.distr)
med(Weight1.5kg.distr)
plot(Weight1.5kg.distr)
```

## Choosing models part 2

## Preference share of the users

## Product profiles

## Conclusion