```
```{r Profiles Graph, echo=FALSE}
## Plot
g <- ggplot(df, aes(Profiles, Freq))
g + geom_bar(stat="identity", width = 0.5, fill="tomato2") +
labs(title="Profiles counting",
caption="Frequency of profiles") +
theme(axis.text.x = element_text(angle=65, vjust=0.6))
```
```{r Function selecting profiles, include=FALSE}
attributes <- list(Price=names(table(laptops.mlogit$Price)),
RAM=names(table(laptops.mlogit$RAM)),
Memory=names(table(laptops.mlogit$Memory)),
Processor=names(table(laptops.mlogit$Processor)),
Weight=names(table(laptops.mlogit$Weight)),
ScreenSize=names(table(laptops.mlogit$ScreenSize)))
allDesign <- expand.grid(attributes)
ProductSelection <- function(Price,RAM,Memory,Processor,Weight,ScreenSize){
ram <-  paste(as.character(RAM), "GB", sep = "")
if(Memory==1) memory <- paste(as.character(Memory), "T", sep = "") else memory <-  paste(as.character(Memory), "GB", sep = "")
processor <-  paste('i',as.character(Processor), sep = "")
weight <-  paste(as.character(Weight), "kg", sep = "")
return(filter(allDesign, Price == {{Price}}, RAM == {{ram}}, Memory == {{ memory }}, Processor == {{ processor }}, Weight == {{ weight }}, ScreenSize == {{ ScreenSize }}))
}
```
### Profiles chosen
```{r include=FALSE}
#Entry market
entry1 <- ProductSelection(Price = 0.7, RAM = 4,Memory = 126,Processor = 3, Weight = 0.8,ScreenSize = 12)
entry2 <- ProductSelection(Price = 1, RAM = 4,Memory = 126,Processor = 3, Weight = 1.2,ScreenSize = 13)
#Mid market
mid1 <- ProductSelection(Price = 1, RAM = 8,Memory = 256,Processor = 5, Weight = 1, ScreenSize = 13)
mid2 <- ProductSelection(Price = 1.5, RAM = 16,Memory = 512,Processor = 7, Weight = 1.5,ScreenSize = 16)
#High end market
high1 <- ProductSelection(Price = 2, RAM = 16,Memory = 512, Processor = 7, Weight = 1.2,ScreenSize = 16)
high2 <- ProductSelection(Price = 2, RAM = 32,Memory = 1, Processor = 9, Weight = 1.5,ScreenSize = 14)
profiles <- rbind(entry1, entry2, mid1, mid2, high1, high2)
```
```{r echo=FALSE}
print(profiles)
```
```{r Predict Function - Uncorrelated fixed effects, include=FALSE}
predict.mnl <- function(model, data) {
# Function for predicting preference shares from a MNL model
# model: mlogit object returned by mlogit()
# data: a data frame containing the set of designs for which you want to
#       predict shares.  Same format at the data used to estimate model.
data.model <- model.matrix(update(model$formula, 0 ~ .), data = data)[,-1]
logitUtility <- data.model%*%model$coef
share <- exp(logitUtility)/sum(exp(logitUtility))
cbind(share, data)
}
```
## Preference share prediction (MNL)
```{r Preference share, echo=FALSE}
predict.mnl(lm2, profiles)
```
```{r Preference share with bootstrap - Fixed model, include=FALSE}
#######################################################################
### Function for predicting preference shares from a MNL model with ###
### bootstrap percentiles prediction intervals                      ###
#######################################################################
# model: mlogit object returned by mlogit()
# data: a data frame containing the set of designs for which you want to
#       predict shares.  Same format of the data used to estimate model.
# nsim: number of bootstrap samples, default is 500
# conflevel: desired confidence level, default is 0.95
# library "parallel" is necessary
BootCI.predict.mnl <- function(model, data, nsim=500, conflevel=0.95) {
dataModel <- model$model
dataModel$probabilities <- NULL
dataModel$linpred <- NULL
idx <- dataModel$idx
dataModel$idx <- NULL
dataModel <- data.frame(dataModel, idx)
idVar <- unique(dataModel[,names(idx)[1]])
bootstrapping <- function(x) {
idbootsamp <- data.frame(sample(idVar, replace=T))
names(idbootsamp) <- names(idx)[1]
bootsamp <- merge(idbootsamp, dataModel, by=names(idx)[1], all.x=T)
bootsamp[,names(idx)[1]] <- rep(1:length(table(idx[,1])), each=length(table(idx[,3])))
bootsamp.mlogit  <- dfidx(bootsamp, idx = list(c(names(idx)[1:2]), names(idx)[3]),
drop.index=F)
bootfit <- update(model, data = bootsamp.mlogit)
data.model <- model.matrix(update(bootfit$formula, 0 ~ .), data = data)[,-1]
logitUtility <- data.model%*%bootfit$coef
share <- exp(logitUtility)/sum(exp(logitUtility))
share
}
cl <- makeCluster(detectCores())
clusterEvalQ(cl, library(mlogit))
clusterExport(cl, varlist=c("idVar", "dataModel", "idx", "model", "data"),
envir=environment())
bootdistr <- parLapply(cl, 1:nsim, fun=bootstrapping)
stopCluster(cl)
bootdistr <- do.call(cbind, bootdistr)
lowl <- (1-conflevel)/2
upl <- 1-lowl
bootperc <- t(apply(bootdistr, 1, function(x) quantile(x, probs=c(lowl, upl))))
pointpred <- predict.mnl(model, data)
predictedShares <- cbind(pointpred[,1], bootperc, pointpred[,2:ncol(pointpred)])
names(predictedShares)[1] <- "share"
predictedShares
}
```
### Preference share with bootstrap - Fixed model
```{r}
BootCI.predict.mnl(lm2,profiles)
```
```{r Sensitivity Function, include=FALSE}
sensitivity.mnl <- function(model, attrib, base.data, competitor.data) {
# Function for creating data for a preference share-sensitivity chart
# model: mlogit object returned by mlogit() function
# attrib: list of vectors with attribute levels to be used in sensitivity
# base.data: data frame containing baseline design of target product
# competitor.data: data frame contining design of competitive set
data <- rbind(base.data, competitor.data)
base.share <- predict.mnl(model, data)[1,1]
share <- NULL
for (a in seq_along(attrib)) {
for (i in attrib[[a]]) {
data[1,] <- base.data
data[1,a] <- i
share <- c(share, predict.mnl(model, data)[1,1])
}
}
data.frame(level=unlist(attrib), share=share, increase=share-base.share)
}
base.data <- profiles[5,]
competitor.data <- profiles[-5,]
tradeoff <- sensitivity.mnl(lm2, attributes, base.data, competitor.data)
```
### Trade-off attributes graph - MNL
```{r Trade-off attributes graph, echo=FALSE}
tradeoff <- sensitivity.mnl(lm2, attributes, base.data, competitor.data)
print(tradeoff)
barplot(tradeoff$increase, horiz=FALSE, names.arg=tradeoff$level,
ylab="Change in Share for the Planned Product Design",
ylim=c(-0.1,0.4))
grid(nx=NA, ny=NULL)
```
## Are users homogeneous?
```{r include=FALSE}
lm2.rpar <- rep("n", length=length(lm2$coef))
names(lm2.rpar) <- names(lm2$coef)
lm2.rpar
```
### Mixed MNL (with Random Effect)
In order to verify that, we are going to create a model that takes in consideration random effects (variation according to respondents).
```{r}
lm2.mixed <- mlogit(choice ~ Price + RAM + Memory + Processor + Weight + ScreenSize  | -1,
data = laptops.mlogit,
panel=TRUE, rpar = lm2.rpar, correlation = FALSE)
summary(lm2.mixed)
```
### Distribution of the random effects - Level of heterogeneity
```{r echo=FALSE}
# We can get a visual summary of the distribution of random effects and hence of the level of heterogeneity
#layout(matrix(c(3,3,2,3), 2, 2, byrow = TRUE))
#par(mfrow=c(2,2))
plot(lm2.mixed)
```
By comparing the sign of the quantiles we can identify that Processori5 and Weight1.5kg have different signs, which could imply heterogeneity
```{r echo=FALSE}
#comparing the sign of the quantiles we can identify that Processori5 and Weight1.5kg have different signs, which could imply heterogeneity
#par(mfrow=c(2,2))
processor5.distr <- rpar(lm2.mixed, "Processori5")
summary(processor5.distr)
#mean(processor5.distr)
#med(processor5.distr)
#plot(processor5.distr)
Weight1.5kg.distr <- rpar(lm2.mixed, "Weight1.5kg")
summary(Weight1.5kg.distr)
#mean(Weight1.5kg.distr)
#med(Weight1.5kg.distr)
#plot(Weight1.5kg.distr)
```
```{r}
par(mfrow=c(2,2))
plot(processor5.distr)
plot(Weight1.5kg.distr)
```
### Correlated model
It is reasonable to think that some variables can be correlated. In order to verify that, we are going to create a model that takes in consideration random effects (variation according to respondents) and that the random parameters are correlated.
First we consider correlation among all pair of variables and analyze the signals of the random coefficients.
```{r Checking correlation}
lm2.mixed2 <- update(lm2.mixed, correlation = TRUE)
summary(lm2.mixed2)
cov2cor(cov.mlogit(lm2.mixed2))
summary(vcov(lm2.mixed2, what = "rpar", type = "cor"))
```
By analysing the signs from random effect coefficients, we can update the model to contain just the variables that are correlated.
```{r Random effect + Correlated}
lm2.mixed3 <- update(lm2.mixed2, correlation = c("Price1.5", "RAM8GB","RAM16GB", "RAM32GB", "Memory256GB","Memory512GB", "Memory1T", "Processori5", "Processori7","Processori9", "Weight1kg", "Weight1.2kg", "Weight1.5kg", "ScreenSize13", "ScreenSize14", "ScreenSize16"))
```
### Choosing models part 2
We need to compare the two new models with the previously chosen one (Fixed effect, no intercept) in order to choose which one to use. Same steps as the first choice of model.
### Fixed effects vs. uncorrelated random effects
```{r echo=FALSE}
lrtest(lm2, lm2.mixed) #Fixed effects vs. uncorrelated random effects
```
### Random effects but Uncorrelated vs. Random effects + all correlated
```{r echo=FALSE}
lrtest(lm2.mixed, lm2.mixed2) #Uncorrelated random effects vs. all correlated random effects
```
###  Random effects + all correlated vs.  Random effects + Partially correlated
```{r echo=FALSE}
lrtest(lm2.mixed2,lm2.mixed3) #partially correlated random effects vs. all correlated random effects
```
## Preference share prediction (Mixed MNL)
```{r Predict Function Correlated Random Effect, include=FALSE}
predict.mixed.mnl <- function(model, data, nresp=1000) {
# Function for predicting shares from a mixed MNL model
# model: mlogit object returned by mlogit()
# data: a data frame containing the set of designs for which you want to
#       predict shares. Same format at the data used to estimate model.
# Note that this code assumes all model parameters are random
data.model <- model.matrix(update(model$formula, 0 ~ .), data = data)[,-1]
coef.Sigma <- cov.mlogit(model)
coef.mu <- model$coef[1:dim(coef.Sigma)[1]]
draws <- mvrnorm(n=nresp, coef.mu, coef.Sigma)
shares <- matrix(NA, nrow=nresp, ncol=nrow(data))
for (i in 1:nresp) {
utility <- data.model%*%draws[i,]
share = exp(utility)/sum(exp(utility))
shares[i,] <- share
}
cbind(colMeans(shares), data)
}
```
```{r}
set.seed(1234)
predict.mixed.mnl(lm2.mixed2, data=profiles)
```
```{r Preference share with bootstrap - Mixed model, include=FALSE}
#######################################################################
### Function for predicting preference shares from a MNL model with ###
### bootstrap percentiles prediction intervals                      ###
#######################################################################
# model: mlogit object returned by mlogit()
# data: a data frame containing the set of designs for which you want to
#       predict shares.  Same format of the data used to estimate model.
# nsim: number of bootstrap samples, default is 500
# conflevel: desired confidence level, default is 0.95
# nresp: number of representative respondents, default is 1000
# library "parallel" is necessary
BootCI.predict.mixed.mnl <- function(model, data, nsim=500, conflevel=0.95, nresp=1000) {
dataModel <- model$model
dataModel$probabilities <- NULL
dataModel$linpred <- NULL
idx <- dataModel$idx
dataModel$idx <- NULL
dataModel <- data.frame(dataModel, idx)
idVar <- unique(dataModel[,names(idx)[1]])
bootstrapping <- function(x) {
idbootsamp <- data.frame(sample(idVar, replace=T))
names(idbootsamp) <- names(idx)[1]
bootsamp <- merge(idbootsamp, dataModel, by=names(idx)[1], all.x=T)
bootsamp[,names(idx)[1]] <- rep(1:length(table(idx[,1])), each=length(table(idx[,3])))
bootsamp.mlogit  <- dfidx(bootsamp, idx = list(c(names(idx)[1:2]), names(idx)[3]),
drop.index=F)
bootfit <- update(model, data = bootsamp.mlogit)
data.model <- model.matrix(update(bootfit$formula, 0 ~ .), data = data)[,-1]
coef.Sigma <- cov.mlogit(bootfit)
coef.mu <- bootfit$coef[1:dim(coef.Sigma)[1]]
draws <- mvrnorm(n=nresp, coef.mu, coef.Sigma)
shares <- matrix(NA, nrow=nresp, ncol=nrow(data))
for (i in 1:nresp) {
utility <- data.model%*%draws[i,]
share <- exp(utility)/sum(exp(utility))
shares[i,] <- share
}
colMeans(shares)
}
cl <- makeCluster(detectCores())
clusterEvalQ(cl, {
library(mlogit)
library(MASS) })
clusterExport(cl, varlist=c("idVar", "dataModel", "idx", "model", "data", "nresp",
paste(model$call$rpar)), envir=environment())
bootdistr <- parLapply(cl, 1:nsim, fun=bootstrapping)
stopCluster(cl)
bootdistr <- do.call(cbind, bootdistr)
lowl <- (1-conflevel)/2
upl <- 1-lowl
bootperc <- t(apply(bootdistr, 1, function(x) quantile(x, probs=c(lowl, upl))))
pointpred <- predict.mixed.mnl(model, data, nresp)
predictedShares <- cbind(pointpred[,1], bootperc, pointpred[,2:ncol(pointpred)])
names(predictedShares)[1] <- "share"
predictedShares
}
```
### Preference share with bootstrap - Mixed model
```{r}
BootCI.predict.mixed.mnl(lm2.mixed2, profiles)
```
### Trade-off attributes graph - Mixed MNL
```{r Trade-off attributes graph, echo=FALSE}
tradeoff <- sensitivity.mnl(lm2.mixed2, attributes, base.data, competitor.data)
print(tradeoff)
barplot(tradeoff$increase, horiz=FALSE, names.arg=tradeoff$level,
ylab="Change in Share for the Planned Product Design",
ylim=c(-0.1,0.4))
grid(nx=NA, ny=NULL)
```
### Effects of individual part and individual-level predictors
In our case we do not have any variable that could be analyzed in the individual-level but we can analyze the individual part. That is, how the respondents chosen
```{r}
PW.ind <- fitted(lm2.mixed2, type = "parameters")
head(PW.ind)
```
## Conclusion
```{r}
```
knitr::opts_chunk$set(echo = TRUE)
library(mlogit)
library(dplyr)
library(ggplot2)
library(MASS)
library(lattice)
library(parallel)
laptops = read.csv("Dataset/laptops.csv", sep=";")
laptops$Price       <- as.factor(laptops$Price)
laptops$RAM         <- factor(laptops$RAM, levels=c( "4GB", "8GB", "16GB", "32GB" ))
laptops$Memory      <- factor(laptops$Memory, levels=c( "126GB", "256GB", "512GB", "1T" ))
laptops$Processor   <- factor(laptops$Processor, levels=c( "i3", "i5", "i7", "i9" ))
laptops$Weight      <- factor(laptops$Weight, levels=c( "0.8kg", "1kg", "1.2kg", "1.5kg" ))
laptops$ScreenSize  <- as.factor(laptops$ScreenSize)
laptops$alt         <- factor(laptops$alt, levels=c("1", "2", "3", "4"))
summary(laptops)
# To check balance, he used this function
sapply(laptops, table)
xtabs(choice ~ Price, data=laptops)
xtabs(choice ~ RAM, data=laptops)
xtabs(choice ~ Memory, data=laptops)
xtabs(choice ~ Processor, data=laptops)
xtabs(choice ~ Weight, data=laptops)
xtabs(choice ~ ScreenSize, data=laptops)
laptops.mlogit <- dfidx(laptops, idx = list(c("ques", "resp.id"), "alt"), drop.index=F, levels=c(1,2,3,4))
lm1 <- mlogit(choice ~ Price + RAM + Memory + Processor + Weight + ScreenSize , data = laptops.mlogit)
summary(lm1)
lm2 <- mlogit(choice ~ Price + RAM + Memory + Processor + Weight + ScreenSize | -1, data = laptops.mlogit)
summary(lm2)
lrtest(lm1, lm2)
print("")
print("Analyze model with price as qualitative vs quantitative")
lm3 <- mlogit(choice ~  as.numeric(as.character(Price)) + RAM + Memory + Processor + Weight + ScreenSize | -1, data = laptops.mlogit)
summary(lm3)
lrtest(lm3, lm2)
coef(lm3)["RAM16GB"]/(coef(lm3)["as.numeric(as.character(Price))"]/1000)
# print("since our p-value is smaller than our significance level(0.05), we cannot use price as quantitative variable. This means that we cannot analyze the willingness-to-pay for each level's attribute.")
#adding index
laptops.chosen <- filter(laptops,laptops$choice == "1")
laptops.indexed <- laptops.chosen
laptops.indexed$id <- paste(as.character(laptops.indexed$Price),"-",
as.character(laptops.indexed$RAM),"-",
as.character(laptops.indexed$Memory),"-",
as.character(laptops.indexed$Processor),"-",
as.character(laptops.indexed$Weight),"-",
as.character(laptops.indexed$ScreenSize), sep = "")
# Profiles more "popular" (top chosen)
freqtable <- table(laptops.indexed$id)
df <- as.data.frame.table(freqtable)
df <- df %>% as.data.frame() %>% top_n(15, Freq) %>% rename(Profiles = Var1)
df <- df[1:15,]
df <- transform(df, Profiles=reorder(Profiles, -Freq))
theme_set(theme_classic())
## Plot
g <- ggplot(df, aes(Profiles, Freq))
g + geom_bar(stat="identity", width = 0.5, fill="tomato2") +
labs(title="Profiles counting",
caption="Frequency of profiles") +
theme(axis.text.x = element_text(angle=65, vjust=0.6))
attributes <- list(Price=names(table(laptops.mlogit$Price)),
RAM=names(table(laptops.mlogit$RAM)),
Memory=names(table(laptops.mlogit$Memory)),
Processor=names(table(laptops.mlogit$Processor)),
Weight=names(table(laptops.mlogit$Weight)),
ScreenSize=names(table(laptops.mlogit$ScreenSize)))
allDesign <- expand.grid(attributes)
ProductSelection <- function(Price,RAM,Memory,Processor,Weight,ScreenSize){
ram <-  paste(as.character(RAM), "GB", sep = "")
if(Memory==1) memory <- paste(as.character(Memory), "T", sep = "") else memory <-  paste(as.character(Memory), "GB", sep = "")
processor <-  paste('i',as.character(Processor), sep = "")
weight <-  paste(as.character(Weight), "kg", sep = "")
return(filter(allDesign, Price == {{Price}}, RAM == {{ram}}, Memory == {{ memory }}, Processor == {{ processor }}, Weight == {{ weight }}, ScreenSize == {{ ScreenSize }}))
}
#Entry market
entry1 <- ProductSelection(Price = 0.7, RAM = 4,Memory = 126,Processor = 3, Weight = 0.8,ScreenSize = 12)
entry2 <- ProductSelection(Price = 1, RAM = 4,Memory = 126,Processor = 3, Weight = 1.2,ScreenSize = 13)
entry3 <- ProductSelection(Price = 0.7, RAM = 8,Memory = 126,Processor = 3, Weight = 1.2,ScreenSize = 14)
entry4 <- ProductSelection(Price = 0.7, RAM = 8,Memory = 1,Processor = 3, Weight = 1.2,ScreenSize = 16)
#Mid market
mid1 <- ProductSelection(Price = 1, RAM = 8,Memory = 256,Processor = 5, Weight = 1, ScreenSize = 13)
mid2 <- ProductSelection(Price = 1.5, RAM = 16,Memory = 512,Processor = 7, Weight = 1.5,ScreenSize = 16)
mid3 <- ProductSelection(Price = 0.7, RAM = 4,Memory = 126,Processor = 5, Weight = 1.2,ScreenSize = 14)
#High end market
high1 <- ProductSelection(Price = 2, RAM = 16,Memory = 512, Processor = 7, Weight = 1.2,ScreenSize = 16)
high2 <- ProductSelection(Price = 2, RAM = 32,Memory = 1, Processor = 9, Weight = 1.5,ScreenSize = 14)
high3 <- ProductSelection(Price = 0.7, RAM = 4,Memory = 1,Processor = 9, Weight = 1,ScreenSize = 16)
profiles <- rbind(entry1, entry2,entry3, entry4, mid1, mid2, mid3, high1, high2, high3)
print(profiles)
predict.mnl <- function(model, data) {
# Function for predicting preference shares from a MNL model
# model: mlogit object returned by mlogit()
# data: a data frame containing the set of designs for which you want to
#       predict shares.  Same format at the data used to estimate model.
data.model <- model.matrix(update(model$formula, 0 ~ .), data = data)[,-1]
logitUtility <- data.model%*%model$coef
share <- exp(logitUtility)/sum(exp(logitUtility))
cbind(share, data)
}
predict.mnl(lm2, profiles)
knitr::opts_chunk$set(echo = TRUE)
library(mlogit)
library(dplyr)
library(ggplot2)
library(MASS)
library(lattice)
library(parallel)
laptops = read.csv("Dataset/laptops.csv", sep=";")
laptops$Price       <- as.factor(laptops$Price)
laptops$RAM         <- factor(laptops$RAM, levels=c( "4GB", "8GB", "16GB", "32GB" ))
laptops$Memory      <- factor(laptops$Memory, levels=c( "126GB", "256GB", "512GB", "1T" ))
laptops$Processor   <- factor(laptops$Processor, levels=c( "i3", "i5", "i7", "i9" ))
laptops$Weight      <- factor(laptops$Weight, levels=c( "0.8kg", "1kg", "1.2kg", "1.5kg" ))
laptops$ScreenSize  <- as.factor(laptops$ScreenSize)
laptops$alt         <- factor(laptops$alt, levels=c("1", "2", "3", "4"))
summary(laptops)
# To check balance, he used this function
sapply(laptops, table)
xtabs(choice ~ Price, data=laptops)
xtabs(choice ~ RAM, data=laptops)
xtabs(choice ~ Memory, data=laptops)
xtabs(choice ~ Processor, data=laptops)
xtabs(choice ~ Weight, data=laptops)
xtabs(choice ~ ScreenSize, data=laptops)
laptops.mlogit <- dfidx(laptops, idx = list(c("ques", "resp.id"), "alt"), drop.index=F, levels=c(1,2,3,4))
lm1 <- mlogit(choice ~ Price + RAM + Memory + Processor + Weight + ScreenSize , data = laptops.mlogit)
summary(lm1)
lm2 <- mlogit(choice ~ Price + RAM + Memory + Processor + Weight + ScreenSize | -1, data = laptops.mlogit)
summary(lm2)
lrtest(lm1, lm2)
print("")
print("Analyze model with price as qualitative vs quantitative")
lm3 <- mlogit(choice ~  as.numeric(as.character(Price)) + RAM + Memory + Processor + Weight + ScreenSize | -1, data = laptops.mlogit)
summary(lm3)
lrtest(lm3, lm2)
coef(lm3)["RAM16GB"]/(coef(lm3)["as.numeric(as.character(Price))"]/1000)
# print("since our p-value is smaller than our significance level(0.05), we cannot use price as quantitative variable. This means that we cannot analyze the willingness-to-pay for each level's attribute.")
#adding index
laptops.chosen <- filter(laptops,laptops$choice == "1")
laptops.indexed <- laptops.chosen
laptops.indexed$id <- paste(as.character(laptops.indexed$Price),"-",
as.character(laptops.indexed$RAM),"-",
as.character(laptops.indexed$Memory),"-",
as.character(laptops.indexed$Processor),"-",
as.character(laptops.indexed$Weight),"-",
as.character(laptops.indexed$ScreenSize), sep = "")
# Profiles more "popular" (top chosen)
freqtable <- table(laptops.indexed$id)
df <- as.data.frame.table(freqtable)
df <- df %>% as.data.frame() %>% top_n(15, Freq) %>% rename(Profiles = Var1)
df <- df[1:15,]
df <- transform(df, Profiles=reorder(Profiles, -Freq))
theme_set(theme_classic())
## Plot
g <- ggplot(df, aes(Profiles, Freq))
g + geom_bar(stat="identity", width = 0.5, fill="tomato2") +
labs(title="Profiles counting",
caption="Frequency of profiles") +
theme(axis.text.x = element_text(angle=65, vjust=0.6))
attributes <- list(Price=names(table(laptops.mlogit$Price)),
RAM=names(table(laptops.mlogit$RAM)),
Memory=names(table(laptops.mlogit$Memory)),
Processor=names(table(laptops.mlogit$Processor)),
Weight=names(table(laptops.mlogit$Weight)),
ScreenSize=names(table(laptops.mlogit$ScreenSize)))
allDesign <- expand.grid(attributes)
ProductSelection <- function(Price,RAM,Memory,Processor,Weight,ScreenSize){
ram <-  paste(as.character(RAM), "GB", sep = "")
if(Memory==1) memory <- paste(as.character(Memory), "T", sep = "") else memory <-  paste(as.character(Memory), "GB", sep = "")
processor <-  paste('i',as.character(Processor), sep = "")
weight <-  paste(as.character(Weight), "kg", sep = "")
return(filter(allDesign, Price == {{Price}}, RAM == {{ram}}, Memory == {{ memory }}, Processor == {{ processor }}, Weight == {{ weight }}, ScreenSize == {{ ScreenSize }}))
}
#Entry market
entry1 <- ProductSelection(Price = 0.7, RAM = 4,Memory = 126,Processor = 3, Weight = 0.8,ScreenSize = 12)
entry2 <- ProductSelection(Price = 1, RAM = 4,Memory = 126,Processor = 3, Weight = 1.2,ScreenSize = 13)
entry3 <- ProductSelection(Price = 0.7, RAM = 8,Memory = 126,Processor = 3, Weight = 1.2,ScreenSize = 14)
entry4 <- ProductSelection(Price = 0.7, RAM = 8,Memory = 1,Processor = 3, Weight = 1.2,ScreenSize = 16)
#Mid market
mid1 <- ProductSelection(Price = 1, RAM = 8,Memory = 256,Processor = 5, Weight = 1, ScreenSize = 13)
mid2 <- ProductSelection(Price = 1.5, RAM = 16,Memory = 512,Processor = 7, Weight = 1.5,ScreenSize = 16)
mid3 <- ProductSelection(Price = 0.7, RAM = 4,Memory = 126,Processor = 5, Weight = 1.2,ScreenSize = 14)
#High end market
high1 <- ProductSelection(Price = 2, RAM = 16,Memory = 512, Processor = 7, Weight = 1.2,ScreenSize = 16)
high2 <- ProductSelection(Price = 2, RAM = 32,Memory = 1, Processor = 9, Weight = 1.5,ScreenSize = 14)
high3 <- ProductSelection(Price = 0.7, RAM = 4,Memory = 1,Processor = 9, Weight = 1,ScreenSize = 16)
profiles <- rbind(entry1, entry2,entry3, entry4, mid1, mid2, mid3, high1, high2, high3)
print(profiles)
predict.mnl <- function(model, data) {
# Function for predicting preference shares from a MNL model
# model: mlogit object returned by mlogit()
# data: a data frame containing the set of designs for which you want to
#       predict shares.  Same format at the data used to estimate model.
data.model <- model.matrix(update(model$formula, 0 ~ .), data = data)[,-1]
logitUtility <- data.model%*%model$coef
share <- exp(logitUtility)/sum(exp(logitUtility))
cbind(share, data)
}
predict.mnl(lm2, profiles)
