---
title: "Laboratory of Consumer and Business Analytics"
subtitle: "Conjoint analysis - Laptop Dataset"
author: 
  - "Nisha Antony"
  - "Sander Martins"
date: "27/01/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r Loading Libraries, include=FALSE}
library(mlogit)
library(dplyr)
library(ggplot2)
library(MASS)
library(lattice)
library(parallel)
```

```{r Loading Dataset, include=FALSE}
laptops = read.csv("Dataset/laptops.csv", sep=";")

```


<!-- Here we are converting the quantitative variables to qualitative before fitting it into the model. WE set 4GB, 126GB, i3, 0.8Kg as ref level for RAM, Memory, Proc and weight resp.This helps us to see how preferences changes overtime when we have higher config as an alternative-->
```{r Preparing data, include=FALSE}
laptops$Price       <- as.factor(laptops$Price)
laptops$RAM         <- factor(laptops$RAM, levels=c( "4GB", "8GB", "16GB", "32GB" ))
laptops$Memory      <- factor(laptops$Memory, levels=c( "126GB", "256GB", "512GB", "1T" ))
laptops$Processor   <- factor(laptops$Processor, levels=c( "i3", "i5", "i7", "i9" ))
laptops$Weight      <- factor(laptops$Weight, levels=c( "0.8kg", "1kg", "1.2kg", "1.5kg" ))
laptops$ScreenSize  <- as.factor(laptops$ScreenSize) 
laptops$alt         <- factor(laptops$alt, levels=c("1", "2", "3", "4"))
```
# Agenda
* Project Description <br/>
* Summary of all the analysis to be presented <br/>
* Dataset description <br/>
* Dataset balanced and Association of attributes<br/>
* Models to fit our data<br/>
* Choosing models part 1<br/>
* Are our users homogeneous?<br/>
* Correlated models<br/>
* Choosing models part 2<br/>
* Preference share of the users<br/>
* Product profiles<br/>
* Conclusion<br/>



## Project Description

The objective of this project is to have an understanding of conjoint analysis and demonstrate some of the conclusion that we be can found using this analysis. In this project, we will analyze the preferences of an individual while purchasing a laptop. When it comes to laptops, we have several options in the market. A customer usually does a thorough research before he/she makes the purchase. The final decision depends on several attributes of the product and its relevance to the customer. We study the relationship between the choice and product attributes. 

## Dataset description
Our dataset represents the generated answers to questionnaires regarding the choice of laptops. It is represented in a long format, in other words, we have a row for each alternatives. We have 4 alternatives each for 7500 questions and 4 levels for each attributes. 

```{r Data description, echo=FALSE}
summary(laptops)
```


## Dataset balanced and Association of attributes

In this part, we check whether the attributes are well balanced.

```{r check balance, echo=FALSE}
# To check balance, he used this function
sapply(laptops, table)
```

Here, the attributes are properly balanced, which means that the frequencies across each levels of the attributes are equally distributed. There is no over/under representation in level of attributes.  

Now we can look into the association of attributes with choice made by the respondent. The xtabs() which provides the joint distribution between two variables is used here.
```{r xtabs - distribution among variables and choice}
xtabs(choice ~ Price, data=laptops)
xtabs(choice ~ RAM, data=laptops)
xtabs(choice ~ Memory, data=laptops)
xtabs(choice ~ Processor, data=laptops)
xtabs(choice ~ Weight, data=laptops)
xtabs(choice ~ ScreenSize, data=laptops)
```


From the joint distribution obtained, we can see that the customers highly prefer laptops with bigger screensize, high memory, a decent RAM of 8GB and i5 processor and are looking for products mostly at price range of 0.7K to 1K.
Very few are opting for laptops with 12" screen or are interested in spending 2K on a laptop.

## Models to fit our data

### Multinomial Logit Model(MNL)

From the dataset, we can gather that the respondent had 4 alternatives to make his/her final choice; implying that the dependent variable is a qualitative multinomial variable with 4 levels. Multinomial Logit model is an appropriate one to fit this kind of data. MNL gives the measurement of association between each attributes and respondent choice.

We use mlogit() function to fit the MNL model. However, the function requires us to organize the data in a special format by using dfidx(). 

```{r dfidx, include=FALSE}
laptops.mlogit <- dfidx(laptops, idx = list(c("ques", "resp.id"), "alt"), drop.index=F, levels=c(1,2,3,4))
```

Now, we assess how attributes affects the choice. In the first model, we will consider the intercept parameters so that we can test the restrictions on them by comparing two models.

```{r MNL}
lm1 <- mlogit(choice ~ Price + RAM + Memory + Processor + Weight + ScreenSize , data = laptops.mlogit)
summary(lm1)
```

In the summary of lm1 model, we can see that the model estimate coefficient of RAM8GB, RAM16GB and RAM32GB with respect to RAM4GB laptops measuring the preference. The laptops with 8GB RAM are more attracted to than RAM of 16GB whereas RAM of 32GB is the least attracted one. Similarly, in terms of memory the coefficients are estimated with respect to Memory126GB. In this case, laptops with 1TB memory has higher preference compared to 126GB When it comes to processors, i3 is taken as the reference value and from the est. coefficient, we can see that i5 is more preferred. The 12-inch and 0.7k is the reference point for screensize and price respectively. Among those attributes, we can see that 16 inch models are far more preferred with respect to 12 inch ones and for the price range, 0.7k itself is most preferred. The est. intercepts provide the preferences for the positions of the alternatives in each question. Here the values corresponding to those intercepts are very small implying that position of alternatives doesn't have much significance. 

### Multinomial Logit Model(MNL) Without Intercept
In order to formally test the significance of the intercept, we fit another model without the intercept parameters and perform a likelihood ratio test comparing both models.

```{r MNL Without Intercept}
lm2 <- mlogit(choice ~ Price + RAM + Memory + Processor + Weight + ScreenSize | -1, data = laptops.mlogit)
summary(lm2)
```

### Choosing models part 1

```{r lrtest(lm1, lm2), echo=FALSE}

lrtest(lm1, lm2)
print("")
```
Here we compare the MNL model with and without estimated intercepts. The comparison between the lm1 and the lm2 with no intercepts leads to a p-value of 0.5133. Since we have a high p-value (in comparison with significance level 0.05), we can conclude that the two models are not significantly different in terms of goodness of fit. This indicates that the alternative specific constants are not necessary to adequately model the data.

```{r Willingness to pay (not available for our data), include=FALSE}
print("Analyze model with price as qualitative vs quantitative")
lm3 <- mlogit(choice ~  as.numeric(as.character(Price)) + RAM + Memory + Processor + Weight + ScreenSize | -1, data = laptops.mlogit)
summary(lm3)
lrtest(lm3, lm2)
coef(lm3)["RAM16GB"]/(coef(lm3)["as.numeric(as.character(Price))"]/1000)
# print("since our p-value is smaller than our significance level(0.05), we cannot use price as quantitative variable. This means that we cannot analyze the willingness-to-pay for each level's attribute.")
```

## Profiles and preference share
### Popular profiles (top 15)

From the survey dataset, we now try to extract the most popular laptop models using a frequency table.

```{r Frequency table, include=FALSE}
#adding index
laptops.chosen <- filter(laptops,laptops$choice == "1")
laptops.indexed <- laptops.chosen
laptops.indexed$id <- paste(as.character(laptops.indexed$Price),"-",
                            as.character(laptops.indexed$RAM),"-",
                            as.character(laptops.indexed$Memory),"-",
                            as.character(laptops.indexed$Processor),"-",
                            as.character(laptops.indexed$Weight),"-",
                            as.character(laptops.indexed$ScreenSize), sep = "")

# Profiles more "popular" (top chosen)
freqtable <- table(laptops.indexed$id)
df <- as.data.frame.table(freqtable)
df <- df %>% as.data.frame() %>% top_n(15, Freq) %>% rename(Profiles = Var1)
df <- df[1:15,]
df <- transform(df, Profiles=reorder(Profiles, -Freq)) 
theme_set(theme_classic())
```

```{r Profiles Graph, echo=FALSE}
## Plot
g <- ggplot(df, aes(Profiles, Freq))
g + geom_bar(stat="identity", width = 0.5, fill="tomato2") + 
  labs(title="Profiles counting", 
       caption="Frequency of profiles") +
  theme(axis.text.x = element_text(angle=65, vjust=0.6))

```

The graph above shows the top 15 popular profiles in the dataset. As we can see most of them are in the price range 0.7k with RAM and memory variants(4GB, 8GB in most cases and 126GB and 1TB respectively).

Next step is to create a subset of designs for which we predict the preference shares. In order to do that, we initially create a set of all possible designs. From these possible designs we select a set of profiles for further studying them.

```{r Function selecting profiles, include=FALSE}
attributes <- list(Price=names(table(laptops.mlogit$Price)),
                   RAM=names(table(laptops.mlogit$RAM)),
                   Memory=names(table(laptops.mlogit$Memory)),
                   Processor=names(table(laptops.mlogit$Processor)),
                   Weight=names(table(laptops.mlogit$Weight)),
                   ScreenSize=names(table(laptops.mlogit$ScreenSize)))
allDesign <- expand.grid(attributes) 

ProductSelection <- function(Price,RAM,Memory,Processor,Weight,ScreenSize){
  ram <-  paste(as.character(RAM), "GB", sep = "")
  if(Memory==1) memory <- paste(as.character(Memory), "T", sep = "") else memory <-  paste(as.character(Memory), "GB", sep = "")
  processor <-  paste('i',as.character(Processor), sep = "")
  weight <-  paste(as.character(Weight), "kg", sep = "")
  
  return(filter(allDesign, Price == {{Price}}, RAM == {{ram}}, Memory == {{ memory }}, Processor == {{ processor }}, Weight == {{ weight }}, ScreenSize == {{ ScreenSize }}))
}
```

### Profiles chosen 


The profiles are chosen based on 3 market levels: entry, mid-range and high performance.

```{r setting profiles, include=FALSE}
#Entry market
entry1 <- ProductSelection(Price = 0.7, RAM = 4,Memory = 126,Processor = 3, Weight = 0.8,ScreenSize = 12)
entry2 <- ProductSelection(Price = 1, RAM = 4,Memory = 126,Processor = 3, Weight = 1.2,ScreenSize = 13)
entry3 <- ProductSelection(Price = 0.7, RAM = 8,Memory = 126,Processor = 3, Weight = 1.2,ScreenSize = 14)
entry4 <- ProductSelection(Price = 0.7, RAM = 8,Memory = 1,Processor = 3, Weight = 1.2,ScreenSize = 16)

#Mid market
mid1 <- ProductSelection(Price = 1, RAM = 8,Memory = 256,Processor = 5, Weight = 1, ScreenSize = 13)
mid2 <- ProductSelection(Price = 1.5, RAM = 16,Memory = 512,Processor = 7, Weight = 1.5,ScreenSize = 16)
mid3 <- ProductSelection(Price = 0.7, RAM = 4,Memory = 126,Processor = 5, Weight = 1.2,ScreenSize = 14)

#High end market
high1 <- ProductSelection(Price = 2, RAM = 16,Memory = 512, Processor = 7, Weight = 1.2,ScreenSize = 16)
high2 <- ProductSelection(Price = 2, RAM = 32,Memory = 1, Processor = 9, Weight = 1.5,ScreenSize = 14)
high3 <- ProductSelection(Price = 0.7, RAM = 4,Memory = 1,Processor = 9, Weight = 1,ScreenSize = 16)

profiles <- rbind(entry1, entry2,entry3, entry4, mid1, mid2, mid3, high1, high2, high3)
```

```{r profiles output, echo=FALSE}
print(profiles)
```

Now that we have chosen the profiles, we create a function to predict the preference shares for the profiles with the estimated model.

```{r Predict Function - Uncorrelated fixed effects, include=FALSE}
predict.mnl <- function(model, data) {
  # Function for predicting preference shares from a MNL model 
  # model: mlogit object returned by mlogit()
  # data: a data frame containing the set of designs for which you want to 
  #       predict shares.  Same format at the data used to estimate model. 
  data.model <- model.matrix(update(model$formula, 0 ~ .), data = data)[,-1] #why do we use updated here?
  logitUtility <- data.model%*%model$coef
  share <- exp(logitUtility)/sum(exp(logitUtility))
  cbind(share, data)
}
```

## Preference share prediction (MNL)
```{r Preference share, echo=FALSE}
predict.mnl(lm2, profiles)
```

#update the numbers of the table bellow.

The table provides the computed preference share for each alternative profiles. Among the selected profiles, we can see that customer may choose the second profile 38.9% of times. Our planned product is the 5th profile which has 8% shares.  These preference shares are made relative to a specific given set of potential competitors and it may change for different set of profiles. Using the est. models we can assess how the updation in the attributes our planned product would affect the preference shares. 

We can further study the impact of variations in the level of attributes by creating a preference share-sensitivity chart. This provides useful indications to the people that have made the design as they get a clear intuitive picture of how changes in the design influence the preference share.

```{r Preference share with bootstrap - Fixed model, include=FALSE}
#######################################################################
### Function for predicting preference shares from a MNL model with ### 
### bootstrap percentiles prediction intervals                      ### 
#######################################################################

# model: mlogit object returned by mlogit()
# data: a data frame containing the set of designs for which you want to 
#       predict shares.  Same format of the data used to estimate model. 
# nsim: number of bootstrap samples, default is 500
# conflevel: desired confidence level, default is 0.95
# library "parallel" is necessary

BootCI.predict.mnl <- function(model, data, nsim=500, conflevel=0.95) {
dataModel <- model$model
dataModel$probabilities <- NULL
dataModel$linpred <- NULL
idx <- dataModel$idx 
dataModel$idx <- NULL
dataModel <- data.frame(dataModel, idx)
idVar <- unique(dataModel[,names(idx)[1]])

bootstrapping <- function(x) {
  idbootsamp <- data.frame(sample(idVar, replace=T))
  names(idbootsamp) <- names(idx)[1]
  bootsamp <- merge(idbootsamp, dataModel, by=names(idx)[1], all.x=T)
  bootsamp[,names(idx)[1]] <- rep(1:length(table(idx[,1])), each=length(table(idx[,3])))
  bootsamp.mlogit  <- dfidx(bootsamp, idx = list(c(names(idx)[1:2]), names(idx)[3]),
                            drop.index=F)    
  bootfit <- update(model, data = bootsamp.mlogit)
  data.model <- model.matrix(update(bootfit$formula, 0 ~ .), data = data)[,-1]
  logitUtility <- data.model%*%bootfit$coef
  share <- exp(logitUtility)/sum(exp(logitUtility))
  share
}

cl <- makeCluster(detectCores())
  clusterEvalQ(cl, library(mlogit))
  clusterExport(cl, varlist=c("idVar", "dataModel", "idx", "model", "data"), 
                envir=environment())
  bootdistr <- parLapply(cl, 1:nsim, fun=bootstrapping)
stopCluster(cl)

bootdistr <- do.call(cbind, bootdistr)
lowl <- (1-conflevel)/2
upl <- 1-lowl  
bootperc <- t(apply(bootdistr, 1, function(x) quantile(x, probs=c(lowl, upl))))
pointpred <- predict.mnl(model, data)
predictedShares <- cbind(pointpred[,1], bootperc, pointpred[,2:ncol(pointpred)])
names(predictedShares)[1] <- "share" 
predictedShares
}
```
### Preference share with bootstrap - Fixed model
```{r predict bootstrap - Fixed model, echo=FALSE}
BootCI.predict.mnl(lm2,profiles)
```


```{r Sensitivity Function, include=FALSE}
sensitivity.mnl <- function(model, attrib, base.data, competitor.data) {
  # Function for creating data for a preference share-sensitivity chart
  # model: mlogit object returned by mlogit() function
  # attrib: list of vectors with attribute levels to be used in sensitivity
  # base.data: data frame containing baseline design of target product
  # competitor.data: data frame contining design of competitive set
  data <- rbind(base.data, competitor.data)
  base.share <- predict.mnl(model, data)[1,1]
  share <- NULL
  for (a in seq_along(attrib)) {
    for (i in attrib[[a]]) {
      data[1,] <- base.data
      data[1,a] <- i
      share <- c(share, predict.mnl(model, data)[1,1])
    }
  }
  data.frame(level=unlist(attrib), share=share, increase=share-base.share)
}

base.data <- profiles[5,]
competitor.data <- profiles[-5,]
tradeoff <- sensitivity.mnl(lm2, attributes, base.data, competitor.data)
```

### Trade-off attributes graph - MNL
```{r Trade-off attributes graph - MNL, echo=FALSE}
tradeoff <- sensitivity.mnl(lm2, attributes, base.data, competitor.data)
print(tradeoff)
barplot(tradeoff$increase, horiz=FALSE, names.arg=tradeoff$level,
        ylab="Change in Share for the Planned Product Design", 
        ylim=c(-0.1,0.4))
grid(nx=NA, ny=NULL)
```

The graph above shows the sensitivity chart for laoptop design with 16GB RAM, 512GB  memory, i7 processor, 16 inch screen size at 2K price range. We can see that, reducing the RAM to 8GB would increase the share by almost 0.23 and increasing the memory from 512GB to 1TB would also increase the preference shares by 0.33. Any change in screen size or weight will have a negative effect on the preference shares.


## Are users homogeneous?

Now we are going to fit mixed MNL model, where the coefficients vary randomly over respondents in the population, rather than being fixed. To estimate a multinomial logit model with random coefficients using "mlogit", we define a vector indicating which coefficients should vary across customers. 

The mlogit() requires a character vector the same length as the coefficient vector with a letter code indicating the  distribution that random coefficients should follow across the respondents: "n" for  normal, "l" for log normal, "t" for truncated normal, and "u" for uniform. For this analysis, we assume that all the coefficients are normally distributed across the population and call our vector "lm2.rpar".

```{r lm2.rpar, include=FALSE}
lm2.rpar <- rep("n", length=length(lm2$coef))
names(lm2.rpar) <- names(lm2$coef)
lm2.rpar
```

### Mixed MNL (with Random Effect)

In order to verify that, we are going to create a model that takes in consideration random effects (variation according to respondents).

```{r Mixed MNL (with Random Effect)}
lm2.mixed <- mlogit(choice ~ Price + RAM + Memory + Processor + Weight + ScreenSize  | -1, 
                   data = laptops.mlogit, 
                   panel=TRUE, rpar = lm2.rpar, correlation = FALSE)
summary(lm2.mixed)
```

In mixed MNL framework, we get a distribution of respondent level values of a parameter for which we can compute the mean and the variance. So we compute 2 parameters to each attributes: we compute the mean and variance corresponding to each distribution respondent variables. In summary, we can see the estimate of mean and std. deviation corresponding to the distribution of each attributes. 

By analyzing the std. deviation, we get the level of variability in customer preference. Higher the est. std. deviation, higher the heterogeneity in the customer preference. The std. deviation can be interpreted by comparing it with our est. mean value. If the absolute std deviation is greater than the absolute mean, we can say we have relevant heterogeneity in consumer preference. Higher the difference between the absolute values, stronger the relevance of heterogeneity. 

In the second table, gives the summary of distribution. If the sign remains the same across all the quantiles, then it indicates that we have a substantial homogeneity in the preferences. Here, the parameters "Weight1.5kg" and "Processori5" has a different signs across the quantiles implying substantial heterogeneity. The other parameters are homogeneous across the quantiles indicating the customer preference in those attributes are homogeneous.  

### Distribution of the random effects - Level of heterogeneity
```{r Distribution of the random effects, echo=FALSE}
# We can get a visual summary of the distribution of random effects and hence of the level of heterogeneity
#layout(matrix(c(3,3,2,3), 2, 2, byrow = TRUE))
#par(mfrow=c(2,2))
plot(lm2.mixed)
```


By comparing the sign of the quantiles we can identify that Processori5 and Weight1.5kg have different signs, which could imply heterogeneity in the customer preferences.


```{r Heterogeneity processor and weight, echo=FALSE}
#comparing the sign of the quantiles we can identify that Processori5 and Weight1.5kg have different signs, which could imply heterogeneity
#par(mfrow=c(2,2))
processor5.distr <- rpar(lm2.mixed, "Processori5")
summary(processor5.distr)
#mean(processor5.distr)
#med(processor5.distr)
#plot(processor5.distr)


Weight1.5kg.distr <- rpar(lm2.mixed, "Weight1.5kg")
summary(Weight1.5kg.distr)
#mean(Weight1.5kg.distr)
#med(Weight1.5kg.distr)
#plot(Weight1.5kg.distr)
```
```{r}
par(mfrow=c(2,2))
plot(processor5.distr)
plot(Weight1.5kg.distr)
```

### Correlated model

It is reasonable to think that some variables can be correlated. In order to verify that, we are going to create a model that takes in consideration random effects (variation according to respondents) and that the random parameters are correlated.
First we consider correlation among all pair of variables and analyze the signals of the random coefficients.
```{r Checking correlation}
lm2.mixed2 <- update(lm2.mixed, correlation = TRUE)
summary(lm2.mixed2)

cov2cor(cov.mlogit(lm2.mixed2))
summary(vcov(lm2.mixed2, what = "rpar", type = "cor"))
```

By analysing the signs from random effect coefficients, we can update the model to contain just the variables that are correlated.

```{r Random effect + Correlated}
lm2.mixed3 <- update(lm2.mixed2, correlation = c("Price1.5", "RAM8GB","RAM16GB", "RAM32GB", "Memory256GB","Memory512GB", "Memory1T", "Processori5", "Processori7","Processori9", "Weight1kg", "Weight1.2kg", "Weight1.5kg", "ScreenSize13", "ScreenSize14", "ScreenSize16"))
```

### Choosing models part 2

We need to compare the two new models with the previously chosen one (Fixed effect, no intercept) in order to choose which one to use. Same steps as the first choice of model.
### Fixed effects vs. uncorrelated random effects
```{r Fixed effects vs. uncorrelated random effects, echo=FALSE}
lrtest(lm2, lm2.mixed) #Fixed effects vs. uncorrelated random effects
```
### Random effects but Uncorrelated vs. Random effects + all correlated
```{r Uncorrelated random effects vs. all correlated random effects, echo=FALSE}
lrtest(lm2.mixed, lm2.mixed2) #Uncorrelated random effects vs. all correlated random effects
```
###  Random effects + all correlated vs.  Random effects + Partially correlated
```{r partially correlated random effects vs. all correlated random effects, echo=FALSE}
lrtest(lm2.mixed2,lm2.mixed3) #partially correlated random effects vs. all correlated random effects
```

## Preference share prediction (Mixed MNL)
```{r Predict Function Correlated Random Effect, include=FALSE}
predict.mixed.mnl <- function(model, data, nresp=1000) {
  # Function for predicting shares from a mixed MNL model 
  # model: mlogit object returned by mlogit()
  # data: a data frame containing the set of designs for which you want to 
  #       predict shares. Same format at the data used to estimate model. 
  # Note that this code assumes all model parameters are random
  data.model <- model.matrix(update(model$formula, 0 ~ .), data = data)[,-1]
  coef.Sigma <- cov.mlogit(model)
  coef.mu <- model$coef[1:dim(coef.Sigma)[1]]
  draws <- mvrnorm(n=nresp, coef.mu, coef.Sigma)
  shares <- matrix(NA, nrow=nresp, ncol=nrow(data))
  for (i in 1:nresp) {
    utility <- data.model%*%draws[i,]
    share = exp(utility)/sum(exp(utility))
    shares[i,] <- share
  }
  cbind(colMeans(shares), data)
}
```

```{r predict no bootstrap, echo=FALSE}
set.seed(1234)
predict.mixed.mnl(lm2.mixed2, data=profiles)
```

```{r Preference share with bootstrap - Mixed model, include=FALSE}
#######################################################################
### Function for predicting preference shares from a MNL model with ### 
### bootstrap percentiles prediction intervals                      ### 
#######################################################################

# model: mlogit object returned by mlogit()
# data: a data frame containing the set of designs for which you want to 
#       predict shares.  Same format of the data used to estimate model. 
# nsim: number of bootstrap samples, default is 500
# conflevel: desired confidence level, default is 0.95
# nresp: number of representative respondents, default is 1000
# library "parallel" is necessary

BootCI.predict.mixed.mnl <- function(model, data, nsim=500, conflevel=0.95, nresp=1000) {
dataModel <- model$model
dataModel$probabilities <- NULL
dataModel$linpred <- NULL
idx <- dataModel$idx 
dataModel$idx <- NULL
dataModel <- data.frame(dataModel, idx)
idVar <- unique(dataModel[,names(idx)[1]])

bootstrapping <- function(x) {
  idbootsamp <- data.frame(sample(idVar, replace=T))
  names(idbootsamp) <- names(idx)[1]
  bootsamp <- merge(idbootsamp, dataModel, by=names(idx)[1], all.x=T)
  bootsamp[,names(idx)[1]] <- rep(1:length(table(idx[,1])), each=length(table(idx[,3])))
  bootsamp.mlogit  <- dfidx(bootsamp, idx = list(c(names(idx)[1:2]), names(idx)[3]),
                            drop.index=F)    
  bootfit <- update(model, data = bootsamp.mlogit)
  data.model <- model.matrix(update(bootfit$formula, 0 ~ .), data = data)[,-1]
  coef.Sigma <- cov.mlogit(bootfit)
  coef.mu <- bootfit$coef[1:dim(coef.Sigma)[1]]
  draws <- mvrnorm(n=nresp, coef.mu, coef.Sigma)
  shares <- matrix(NA, nrow=nresp, ncol=nrow(data))
  for (i in 1:nresp) {
    utility <- data.model%*%draws[i,]
    share <- exp(utility)/sum(exp(utility))
    shares[i,] <- share
  }
  colMeans(shares)
}

cl <- makeCluster(detectCores())
  clusterEvalQ(cl, {
                library(mlogit)
                library(MASS) })
  clusterExport(cl, varlist=c("idVar", "dataModel", "idx", "model", "data", "nresp", 
                paste(model$call$rpar)), envir=environment())
  bootdistr <- parLapply(cl, 1:nsim, fun=bootstrapping)
stopCluster(cl)

bootdistr <- do.call(cbind, bootdistr)
lowl <- (1-conflevel)/2
upl <- 1-lowl  
bootperc <- t(apply(bootdistr, 1, function(x) quantile(x, probs=c(lowl, upl))))
pointpred <- predict.mixed.mnl(model, data, nresp)
predictedShares <- cbind(pointpred[,1], bootperc, pointpred[,2:ncol(pointpred)])
names(predictedShares)[1] <- "share" 
predictedShares
}
```
### Preference share with bootstrap - Mixed model
```{r predict bootstrap output - Mixed model, echo=FALSE}
BootCI.predict.mixed.mnl(lm2.mixed2, profiles)
```

### Trade-off attributes graph - Mixed MNL
```{r Trade-off attributes graph - Mixed MNL, echo=FALSE}
tradeoff <- sensitivity.mnl(lm2.mixed2, attributes, base.data, competitor.data)
print(tradeoff)
barplot(tradeoff$increase, horiz=FALSE, names.arg=tradeoff$level,
        ylab="Change in Share for the Planned Product Design", 
        ylim=c(-0.1,0.4))
grid(nx=NA, ny=NULL)
```


### Effects of individual part and individual-level predictors
In our case we do not have any variable that could be analyzed in the individual-level but we can analyze the individual part. That is, how the respondents chosen
```{r individual part, echo=FALSE}
PW.ind <- fitted(lm2.mixed2, type = "parameters")
head(PW.ind)
```

## Conclusion
```{r}

```

