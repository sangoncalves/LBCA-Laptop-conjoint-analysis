---
title: "Laboratory of Consumer and Business Analytics"
subtitle: "Conjoint analysis - Laptop Dataset"
author: 
  - "Nisha Antony"
  - "Sander Martins"
date: "27/01/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r Loading Libraries, include=FALSE}
library(mlogit)
library(dplyr)
library(ggplot2)
library(MASS)
library(lattice)
library(parallel)
```

```{r Loading Dataset, include=FALSE}
laptops = read.csv("Dataset/laptops.csv", sep=";")

```


<!-- Here we are converting the quantitative variables to qualitative before fitting it into the model. WE set 4GB, 126GB, i3, 0.8Kg as ref level for RAM, Memory, Proc and weight resp.This helps us to see how preferences changes overtime when we have higher config as an alternative-->
```{r Preparing data, include=FALSE}
laptops$Price       <- as.factor(laptops$Price)
laptops$RAM         <- factor(laptops$RAM, levels=c( "4GB", "8GB", "16GB", "32GB" ))
laptops$Memory      <- factor(laptops$Memory, levels=c( "126GB", "256GB", "512GB", "1T" ))
laptops$Processor   <- factor(laptops$Processor, levels=c( "i3", "i5", "i7", "i9" ))
laptops$Weight      <- factor(laptops$Weight, levels=c( "0.8kg", "1kg", "1.2kg", "1.5kg" ))
laptops$ScreenSize  <- as.factor(laptops$ScreenSize) 
laptops$alt         <- factor(laptops$alt, levels=c("1", "2", "3", "4"))
```
# Agenda
* Project Description <br/>
* Summary of all the analysis to be presented <br/>
* Dataset description <br/>
* Dataset balanced and Association of attributes<br/>
* Models to fit our data<br/>
* Choosing models part 1<br/>
* Are our users homogeneous?<br/>
* Correlated models<br/>
* Choosing models part 2<br/>
* Preference share of the users<br/>
* Product profiles<br/>
* Conclusion<br/>



## Project Description

The objective of this project is to have an understanding of conjoint analysis and demonstrate some of the conclusion that we be can found using this analysis. In this project, we will analyze the preferences of an individual while purchasing a laptop. When it comes to laptops, we have several options in the market. A customer usually does a thorough research before he/she makes the purchase. The final decision depends on several attributes of the product and its relevance to the customer. We study the relationship between the choice and product attributes. 

## Dataset description
Our dataset represents the generated answers to questionnaires regarding the choice of laptops. It is represented in a long format, in other words, we have a row for each alternatives. We have 4 alternatives each for 7500 questions and 4 levels for each attributes. 

```{r Data description, echo=FALSE}
summary(laptops)
```


## Dataset balanced and Association of attributes

In this part, we check whether the attributes are well balanced.

```{r check balance, echo=FALSE}
# To check balance, he used this function
bal <- sapply(laptops, table)
print(bal$Price)
print(bal$RAM)
print(bal$Memory)
print(bal$Processor)
print(bal$Weight)
print(bal$ScreenSize)
```

Here, the attributes are properly balanced, which means that the frequencies across each levels of the attributes are equally distributed. There is no over/under representation in level of attributes.  

Now we can look into the association of attributes with choice made by the respondent. The xtabs() which provides the joint distribution between two variables is used here.
```{r xtabs - distribution among variables and choice}
xtabs(choice ~ Price, data=laptops)
xtabs(choice ~ RAM, data=laptops)
xtabs(choice ~ Memory, data=laptops)
xtabs(choice ~ Processor, data=laptops)
xtabs(choice ~ Weight, data=laptops)
xtabs(choice ~ ScreenSize, data=laptops)
```


From the joint distribution obtained, we can see that the customers highly prefer laptops with bigger screensize, high memory, a decent RAM of 8GB and i5 processor and are looking for products mostly at price range of 0.7K to 1K.
It is also in interesting to see that laptops with 126GB memory is the second popular on after 1TB. Very few are opting for laptops with 12" screen or are interested in spending 2K on a laptop. 

## Models to fit our data

### Multinomial Logit Model(MNL)

From the dataset, we can gather that the respondent had 4 alternatives to make his/her final choice; implying that the dependent variable is a qualitative multinomial variable with 4 levels. Multinomial Logit model (MNL) is an appropriate one to fit this kind of data. MNL gives the measurement of association between each attributes and respondent choice.

We use mlogit() function to fit the MNL model. However, the function requires us to organize the data in a special format by using dfidx(). 

```{r dfidx, include=FALSE}
laptops.mlogit <- dfidx(laptops, idx = list(c("ques", "resp.id"), "alt"), drop.index=F, levels=c(1,2,3,4))
```

Now, we assess how attributes affects the choice. In the first model, we will consider the intercept parameters so that we can test the restrictions on them by comparing two models.

```{r MNL}
lm1 <- mlogit(choice ~ Price + RAM + Memory + Processor + Weight + ScreenSize , data = laptops.mlogit)
summary(lm1)
```

The models output have several parameters and values similar to binomial logit model. The *Estimate* column provides the estimated average part worths for each level; they have to be interpreted with respect to the reference level of each attribute.

In the summary of lm1 model, we can see that the model estimate coefficient of RAM8GB, RAM16GB and RAM32GB with respect to RAM4GB laptops measuring the preference. The laptops with 8GB RAM are more preferred than RAM of 4GB(which is the reference level) whereas RAM of 32GB and 16GB has negative sign, which indicates that customers were  less attracted to those when compared to our reference level. Similarly, in terms of memory the coefficients are estimated with respect to Memory126GB. In this case, laptops with 1TB memory has higher preference compared to 126GB. When it comes to processors, i3 is taken as the reference value and from the est. coefficient, we can see that i5 is more preferred. The 12-inch and 0.7k is the reference point for screensize and price respectively. Among those attributes, we can see that 16 inch models are far more preferred with respect to 12 inch ones and for the price range, 0.7k itself is most preferred. The est. intercepts provide the preferences for the positions of the alternatives in each question. Here the values corresponding to those intercepts are very small implying that position of alternatives doesn't have much significance. 

### Multinomial Logit Model(MNL) Without Intercept
In order to formally test the significance of the intercept, we fit another model without the intercept parameters and perform a likelihood ratio test comparing both models.

```{r MNL Without Intercept}
lm2 <- mlogit(choice ~ Price + RAM + Memory + Processor + Weight + ScreenSize | -1, data = laptops.mlogit)
summary(lm2)
```

### Choosing models part 1

```{r lrtest(lm1, lm2), echo=FALSE}
lrtest(lm1, lm2)
```
Here we compare the MNL model with and without estimated intercepts. The comparison between the lm1 and the lm2 with no intercepts leads to a p-value of 0.5133. Since we have a high p-value (in comparison with significance level 0.05), we can conclude that the two models are not significantly different in terms of goodness of fit. This indicates that the alternative specific constants are not necessary to adequately model the data.

## Profiles and preference share
### Popular profiles (top 15)

From the survey dataset, we now try to extract the most popular laptop models using a frequency table.

```{r Frequency table, include=FALSE}
#adding index
laptops.chosen <- filter(laptops,laptops$choice == "1")
laptops.indexed <- laptops.chosen
laptops.indexed$id <- paste(as.character(laptops.indexed$Price),"-",
                            as.character(laptops.indexed$RAM),"-",
                            as.character(laptops.indexed$Memory),"-",
                            as.character(laptops.indexed$Processor),"-",
                            as.character(laptops.indexed$Weight),"-",
                            as.character(laptops.indexed$ScreenSize), sep = "")

# Profiles more "popular" (top chosen)
freqtable <- table(laptops.indexed$id)
df <- as.data.frame.table(freqtable)
df <- df %>% as.data.frame() %>% top_n(15, Freq) %>% rename(Profiles = Var1)
df <- df[1:15,]
df <- transform(df, Profiles=reorder(Profiles, -Freq)) 
theme_set(theme_classic())
```

```{r Profiles Graph, echo=FALSE}
## Plot
g <- ggplot(df, aes(Profiles, Freq))
g + geom_bar(stat="identity", width = 0.5, fill="tomato2") + 
  labs(title="Profiles counting", 
       caption="Frequency of profiles") +
  theme(axis.text.x = element_text(angle=65, vjust=0.6))

```

The graph above shows the top 15 popular profiles in the dataset. As we can see most of them are in the price range 0.7k with RAM and memory variants(4GB, 8GB in most cases and 126GB and 1TB respectively).

Next step is to create a subset of designs for which we predict the preference shares. In order to do that, we initially create a set of all possible designs. From these possible designs we select a set of profiles for further studying them.

```{r Function selecting profiles, include=FALSE}
attributes <- list(Price=names(table(laptops.mlogit$Price)),
                   RAM=names(table(laptops.mlogit$RAM)),
                   Memory=names(table(laptops.mlogit$Memory)),
                   Processor=names(table(laptops.mlogit$Processor)),
                   Weight=names(table(laptops.mlogit$Weight)),
                   ScreenSize=names(table(laptops.mlogit$ScreenSize)))
allDesign <- expand.grid(attributes) 

ProductSelection <- function(Price,RAM,Memory,Processor,Weight,ScreenSize){
  ram <-  paste(as.character(RAM), "GB", sep = "")
  if(Memory==1) memory <- paste(as.character(Memory), "T", sep = "") else memory <-  paste(as.character(Memory), "GB", sep = "")
  processor <-  paste('i',as.character(Processor), sep = "")
  weight <-  paste(as.character(Weight), "kg", sep = "")
  
  return(filter(allDesign, Price == {{Price}}, RAM == {{ram}}, Memory == {{ memory }}, Processor == {{ processor }}, Weight == {{ weight }}, ScreenSize == {{ ScreenSize }}))
}
```

### Profiles chosen 

The profiles are chosen based on 3 market levels: entry, mid-range and high performance.

```{r setting profiles, include=FALSE}
#Entry market
entry1 <- ProductSelection(Price = 0.7, RAM = 4,Memory = 126,Processor = 3, Weight = 0.8,ScreenSize = 12)
entry2 <- ProductSelection(Price = 1, RAM = 4,Memory = 126,Processor = 3, Weight = 1.2,ScreenSize = 13)
entry3 <- ProductSelection(Price = 0.7, RAM = 8,Memory = 126,Processor = 3, Weight = 1.2,ScreenSize = 14)
entry4 <- ProductSelection(Price = 0.7, RAM = 8,Memory = 1,Processor = 3, Weight = 1.2,ScreenSize = 16)

#Mid market
mid1 <- ProductSelection(Price = 1, RAM = 8,Memory = 256,Processor = 5, Weight = 1, ScreenSize = 13)
mid2 <- ProductSelection(Price = 1.5, RAM = 16,Memory = 512,Processor = 7, Weight = 1.5,ScreenSize = 16)
mid3 <- ProductSelection(Price = 0.7, RAM = 4,Memory = 126,Processor = 5, Weight = 1.2,ScreenSize = 14)

#High end market
high1 <- ProductSelection(Price = 2, RAM = 16,Memory = 512, Processor = 7, Weight = 1.2,ScreenSize = 16)
high2 <- ProductSelection(Price = 2, RAM = 32,Memory = 1, Processor = 9, Weight = 1.5,ScreenSize = 14)
high3 <- ProductSelection(Price = 0.7, RAM = 4,Memory = 1,Processor = 9, Weight = 1,ScreenSize = 16)

profiles <- rbind(mid1,entry1, entry2,entry3, entry4, mid2, mid3, high1, high2, high3)
```

```{r profiles output, echo=FALSE}
print(profiles)
```

Now that we have chosen the profiles, we create a function to predict the preference shares for the profiles with the estimated model.

```{r Predict Function - Uncorrelated fixed effects, include=FALSE}
predict.mnl <- function(model, data) {
  # Function for predicting preference shares from a MNL model 
  # model: mlogit object returned by mlogit()
  # data: a data frame containing the set of designs for which you want to 
  #       predict shares.  Same format at the data used to estimate model. 
  data.model <- model.matrix(update(model$formula, 0 ~ .), data = data)[,-1] 
  logitUtility <- data.model%*%model$coef
  share <- exp(logitUtility)/sum(exp(logitUtility))
  cbind(share, data)
}
```

## Preference share prediction (MNL)
```{r Preference share, echo=FALSE}
predict.mnl(lm2, profiles)
```

The table provides the computed preference share for each alternative profiles. Among the selected profiles, we can see that customer may choose the 5th profile 58.9% of times. Our planned product is the 1st profile which has 1% shares.  These preference shares are made relative to a specific given set of potential competitors and it may change for different set of profiles. Using the estimated model we can assess how the updation in the attributes our planned product would affect the preference shares. 

We can further study the impact of variations in the level of attributes by creating a preference share-sensitivity chart. This provides useful indications to the people that have made the design as they get a clear intuitive picture of how changes in the design influence the preference share.

```{r}
source("BootCI.predict.mnl.R")
```

This function is to obtain the Bootstrap Confidence Intervals, it will re-estimate the models and calculate the preference share several times. Here we estimate the model for random samples and obtain the values estimated corresponding to each parameters. From this we will obtain the bootstrap distribution from which we can get the CI. The function takes model(which should be used to compute preference share), chosen set of profiles. Among these chosen profiles, the first one will be our profile, which is to be assessed while comparing with other products that dominates the market. In short, we are trying to find the preference share of our profile in comparison with other product profiles. By default the function as 500 simulations with 95% CI. So this function will return the preference shares along with the bootstrap CI corresponding to each profiles. 

### Preference share with bootstrap - Fixed model
```{r predict bootstrap - Fixed model, echo=FALSE}
BootCI.predict.mnl(lm2,profiles)
```

Preference share is a parameter that help us to understand which profiles are appreciated more by the customers. It can also be used to analyze the importance of attributes. We perform sensitivity analysis to study the attributes; how preference share is affected by the variations in the attributes. 

```{r Sensitivity Function, include=FALSE}
sensitivity.mnl <- function(model, attrib, base.data, competitor.data) {
  # Function for creating data for a preference share-sensitivity chart
  # model: mlogit object returned by mlogit() function
  # attrib: list of vectors with attribute levels to be used in sensitivity
  # base.data: data frame containing baseline design of target product
  # competitor.data: data frame contining design of competitive set
  data <- rbind(base.data, competitor.data)
  base.share <- predict.mnl(model, data)[1,1]
  share <- NULL
  for (a in seq_along(attrib)) {
    for (i in attrib[[a]]) {
      data[1,] <- base.data
      data[1,a] <- i
      share <- c(share, predict.mnl(model, data)[1,1])
    }
  }
  data.frame(level=unlist(attrib), share=share, increase=share-base.share)
}

base.data <- profiles[1,]
competitor.data <- profiles[-1,]
tradeoff <- sensitivity.mnl(lm2, attributes, base.data, competitor.data)
```

The preference shares are in logit scale it difficult to interpret it. Thus we use sensitivity analysis by studying how preference share changes as each level of each attributes are changed one after the other. This function intakes the model, attributes, reference profile: one which is used to study the sensitivity of attributes and competitive set of profiles as the input. 

### Trade-off attributes graph - MNL
```{r Trade-off attributes graph - MNL, echo=FALSE}
tradeoff <- sensitivity.mnl(lm2, attributes, base.data, competitor.data)
print(tradeoff)
barplot(tradeoff$increase, horiz=FALSE, names.arg=tradeoff$level,
        ylab="Change in Share for the Planned Product Design", 
        ylim=c(-0.1,0.4))
grid(nx=NA, ny=NULL)
```

The graph above is the sensitivity chart with price - 1k, RAM - 8GB, memory - 256GB, processor -	i5, weight - 1kg, screensize -	13" as reference profile configuration. We can see that, increasing the memory from 256GB to 1TB would also increase the preference shares by 11% and increasing the screensize to 16" can also increase the preference share by 2.58%. Any change in RAM size, processor or weight will have a negative effect on the preference shares. 

## Are users homogeneous?

Now we are going to fit mixed MNL model, where the coefficients vary randomly over respondents in the population, rather than being fixed. To estimate a multinomial logit model with random coefficients using "mlogit", we define a vector indicating which coefficients should vary across customers. 

The mlogit() requires a character vector the same length as the coefficient vector with a letter code indicating the  distribution that random coefficients should follow across the respondents: "n" for  normal, "l" for log normal, "t" for truncated normal, and "u" for uniform. For this analysis, we assume that all the coefficients are normally distributed across the population and call our vector "lm2.rpar".

```{r lm2.rpar, include=FALSE}
lm2.rpar <- rep("n", length=length(lm2$coef))
names(lm2.rpar) <- names(lm2$coef)
lm2.rpar
```

### Mixed MNL (with Random Effect)

In order to verify that, we are going to create a model that takes in consideration random effects (variation according to respondents).

```{r Mixed MNL (with Random Effect)}
lm2.mixed <- mlogit(choice ~ Price + RAM + Memory + Processor + Weight + ScreenSize  | -1, 
                   data = laptops.mlogit, 
                   panel=TRUE, rpar = lm2.rpar, correlation = FALSE)
summary(lm2.mixed)
# summary(lm2.mixed)$CoefTable[summary(lm2.mixed)$CoefTable[,4]<=0.05, ]
```

In mixed MNL framework, we get a distribution of respondent level values of a parameter for which we can compute the mean and the variance. So we compute 2 parameters to each attributes: we compute the mean and variance corresponding to each distribution respondent variables. In summary, we can see the estimate of mean and std. deviation corresponding to the distribution of each attributes. 

By analyzing the std. deviation, we get the level of variability in customer preference. Higher the est. std. deviation, higher the heterogeneity in the customer preference. The std. deviation can be interpreted by comparing it with our est. mean value. If the absolute std deviation is greater than the absolute mean, we can say we have relevant heterogeneity in consumer preference. Higher the difference between the absolute values, stronger the relevance of heterogeneity. 

In the second table, gives the summary of distribution. If the sign remains the same across all the quantiles, then it indicates that we have a substantial homogeneity in the preferences. Here, the parameters "Weight1.5kg" and "Processori5" has a different signs across the quantiles implying substantial heterogeneity. The other parameters are homogeneous across the quantiles indicating the customer preference in those attributes are homogeneous.  

### Analysing heterogeneity

By comparing the sign of the quantiles we can identify that Processori5 and Weight1.5kg have different signs, which could imply heterogeneity in the customer preferences.

```{r Heterogeneity processor and weight, echo=FALSE}
#comparing the sign of the quantiles we can identify that Processori5 and Weight1.5kg have different signs, which could imply heterogeneity
#par(mfrow=c(2,2))
processor5.distr <- rpar(lm2.mixed, "Processori5")
summary(processor5.distr)
#mean(processor5.distr)
#med(processor5.distr)
#plot(processor5.distr)


Weight1.5kg.distr <- rpar(lm2.mixed, "Weight1.5kg")
summary(Weight1.5kg.distr)
#mean(Weight1.5kg.distr)
#med(Weight1.5kg.distr)
#plot(Weight1.5kg.distr)
```
```{r}
par(mfrow=c(2,2))
plot(processor5.distr)
plot(Weight1.5kg.distr)
```

### Correlated model

It is reasonable to think that some variables can be correlated. In order to verify that, we are going to create a model that takes in consideration random effects (variation according to respondents) and that the random parameters are correlated.
First we consider correlation among all pair of variables and analyze the signals of the random coefficients.
```{r Checking correlation, echo=TRUE}
lm2.mixed2 <- update(lm2.mixed, correlation = TRUE)
# summary(lm2.mixed2)
# summary(lm2.mixed2)$CoefTable[summary(lm2.mixed2)$CoefTable[,4]<=0.05, ]
```

```{r}
cov2cor(cov.mlogit(lm2.mixed2))
summary(vcov(lm2.mixed2, what = "rpar", type = "cor"))
```

By analyzing the signs from random effect coefficients, we can update the model to contain just the variables that are correlated.

```{r Random effect + Correlated}
lm2.mixed3 <- update(lm2.mixed2, correlation = c("Price1.5", "RAM8GB","RAM16GB", "RAM32GB", "Memory256GB","Memory512GB", "Memory1T", "Processori5", "Processori7","Processori9", "Weight1kg", "Weight1.2kg", "Weight1.5kg", "ScreenSize13", "ScreenSize14", "ScreenSize16"))
```

### Choosing models part 2

We need to compare the two new models with the previously chosen one (Fixed effect, no intercept) in order to choose which one to use. Same steps as the first choice of model.
### Fixed effects vs. uncorrelated random effects
```{r Fixed effects vs. uncorrelated random effects, echo=FALSE}
lrtest(lm2, lm2.mixed) #Fixed effects vs. uncorrelated random effects
```

Here we are compare the multinomial model with fixed attributes and the model with uncorrelated random effects. The p-value is very low (~ 0) which implies, we have enough sample evidence to reject the null hypothesis that variances with random effects are 0. That is random effects is significant in explaining consumer preferences. In this case, model that consider heterogeneity is found to be a better fit than the model that assume the homogeneity.

### Random effects but Uncorrelated vs. Random effects + all correlated
```{r Uncorrelated random effects vs. all correlated random effects, echo=FALSE}
lrtest(lm2.mixed, lm2.mixed2) #Uncorrelated random effects vs. all correlated random effects
```

Since we established that models with random effects are better fit, now we can compare the model with uncorrelated random effects with the model with all correlated random effects. From the Likelihood ratio test, we get a low p-value which implies, the random effects are not independent.
The preferences of certain levels are likely associated to preferences of other levels. So we can say that, model with correlated random effects is a better fit than uncorrelated one.

###  Random effects + all correlated vs.  Random effects + Partially correlated
```{r partially correlated random effects vs. all correlated random effects, echo=FALSE}
lrtest(lm2.mixed2,lm2.mixed3) #partially correlated random effects vs. all correlated random effects
```

The lm2.mixed2 is the multinomial model with all correlated random effects whereas lm2.mixed3 is a restricted model with some of the correlated random effects. This test is to determine whether the restricted model is better fit than the model with larger model. 

We obtain a low p-value from the LR test which implies assessing consumer preferences using the model with all correlated random effects (larger model) is a better fit. So among all the models we have seen so far, lm2.mixed2 is the best model for assessing the consumer preferences.

## Preference share prediction (Mixed MNL)

Since we are using a new model, we can try to recalculate the preference in order to analyse if there is any variance.

```{r Predict Function Correlated Random Effect, include=FALSE}
predict.mixed.mnl <- function(model, data, nresp=1000) {
  # Function for predicting shares from a mixed MNL model 
  # model: mlogit object returned by mlogit()
  # data: a data frame containing the set of designs for which you want to 
  #       predict shares. Same format at the data used to estimate model. 
  # Note that this code assumes all model parameters are random
  data.model <- model.matrix(update(model$formula, 0 ~ .), data = data)[,-1]
  coef.Sigma <- cov.mlogit(model)
  coef.mu <- model$coef[1:dim(coef.Sigma)[1]]
  draws <- mvrnorm(n=nresp, coef.mu, coef.Sigma)
  shares <- matrix(NA, nrow=nresp, ncol=nrow(data))
  for (i in 1:nresp) {
    utility <- data.model%*%draws[i,]
    share = exp(utility)/sum(exp(utility))
    shares[i,] <- share
  }
  cbind(colMeans(shares), data)
}
```

```{r predict no bootstrap, echo=FALSE}
set.seed(1234)
predict.mixed.mnl(lm2.mixed2, data=profiles)
```

#Computing the preference share of the New Product profile

Here we are estimating the preference share of product profile with some proposed changes that can 
increase its acceptance rate. So our new reference profile will have an updation in the price and memory attributes, from 1K to 1.5K and 256GB to 1T respectively.


```{r}
proposed.profile <- ProductSelection(Price = 1.5, RAM = 8,Memory = 1,Processor = 5, Weight = 1, ScreenSize = 13)
profiles.new <- rbind(proposed.profile,entry1, entry2,entry3, entry4, mid2, mid3, high1, high2, high3)
set.seed(1234)
predict.mixed.mnl(lm2.mixed2, data=profiles.new)

```

## Conclusion

The attributes that presented properties of heterogeneity were weight (1.5) and processor (i5). The model chosen as the best representing our data was "Random effects + all correlated attributes" (lm2.mixed2).Also, the attribute that represents the biggest change in preference in relation to our selected profile was "*memory 1T*" (~12%). 

One of the strategies that we could persue, if our production allows, is to increase the price from 1K to 1.5K and increase the memory from 256GB to 1T. If we use this strategy we could have a significant increase of preference share which nulifies the effect of the price increment on it. In this case, the preference share will change from ~*1.5%* to *16%*.



